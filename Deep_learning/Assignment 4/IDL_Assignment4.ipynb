{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wtSADyaQ3SF"
   },
   "source": [
    "# **IDL Assignment 4 - DenseNets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3fVxBd5HocV"
   },
   "source": [
    "## **Assigning Tensorflow version and importing the libraries required for the tasks**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "3g1v3YHPFgiV",
    "outputId": "1fc6c25d-d0e4-4e77-d0e4-e2595bdb5c71"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZqgaqJz2HoAM",
    "outputId": "51133a9f-e8db-4aba-ee27-21db735c435b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfXS6CZD62lU"
   },
   "source": [
    "## **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "18HxS0Sq4dJp",
    "outputId": "b14b749b-94fb-4d36-d565-f80fe03b4033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 546s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "M4JoElkz7v0b",
    "outputId": "e380d28c-afa3-4e09-b4f7-0e4f94db32a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f036a37288>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[7], cmap=plt.cm.binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XhZxPPz7VVo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# this is now different\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "\n",
    "# things we really gotta do:\n",
    "# - normalize the images to [0, 1] (first convert to float)\n",
    "# - reshape images from (28, 28) to (784,) (although we could do this later!)\n",
    "# - convert labels to int32 (otherwise tensorflow is gonna be sad :( )\n",
    "\n",
    "#train_images = (train_images.astype(np.float32) / 255.).reshape((-1, 784))\n",
    "#test_images = (test_images.astype(np.float32) / 255.).reshape((-1, 784))\n",
    "train_images = (train_images.astype(np.float32) / 255.)\n",
    "test_images = (test_images.astype(np.float32) / 255.)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32).reshape((-1,))\n",
    "test_labels = test_labels.astype(np.int32).reshape((-1,))\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8v6ZsAtg8i6N",
    "outputId": "42ee0630-e41c-47f6-b572-a4da7410fa3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((32, 32, 3), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFRLy9TYEeKQ"
   },
   "outputs": [],
   "source": [
    "## Declare the sizes of batch, shuffle and repeat\n",
    "\n",
    "SHUFFLE_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "REPEAT_TIMES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5JAavDtD_cu"
   },
   "outputs": [],
   "source": [
    "def batch_shuffle_repeat(data):\n",
    "\n",
    "\n",
    "    data = data.shuffle(SHUFFLE_SIZE, reshuffle_each_iteration= True)\n",
    "    data = data.batch(BATCH_SIZE)    \n",
    "    #data = data.repeat(REPEAT_TIMES)\n",
    "\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyyEwmin_pDP"
   },
   "outputs": [],
   "source": [
    "train_data = batch_shuffle_repeat(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nm-8yNhwytO-"
   },
   "outputs": [],
   "source": [
    "test_data = test_data.shuffle(SHUFFLE_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nkGjoL-x9Uuc",
    "outputId": "4dd6729c-428d-496a-e457-14393682d819"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lVOI2YJtjQjA"
   },
   "source": [
    "## Training of the CNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3BuQPNqMUoZ"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "**Indicators**\n",
    "C - Convolution layer |\n",
    "D - Dropout layer |\n",
    "P - MaxPool layer |\n",
    "F - Flatten\n",
    "\n",
    "1. C(32,3);D(0.2);Dense(5 layers,32 channels each, 3filter size);C(32,3);P(2);D(0.3);Dense(5 layers,32 channels each, 3filter size);C(32,3);P(2);D(0.4);Dense(5 layers,32 channels each, 3filter size);P(2);F \n",
    "\n",
    "      **epochs - 5**\n",
    "      **Test Accuracy -- 70.74**\n",
    "\n",
    "2. C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2);P(2);D(0.3);Dense(5 layers,32 channels each, 2filter size);C(128,3);P(2);D(0.4);Dense(5 layers,32 channels each, 3filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 77.50**\n",
    "\n",
    "3. C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2);P(2);D(0.3);Dense(5 layers,64 channels each, 2filter size);C(128,3);P(2);D(0.4);Dense(5 layers,128 channels each, 3filter size);P(2);F \n",
    "\n",
    "      **epochs - 50**\n",
    "      **Test Accuracy -- 73.42**\n",
    "\n",
    "\n",
    "4. C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2);P(2);D(0.3);Dense(5 layers,64 channels each, 2filter size);C(128,3);P(2);D(0.4);Dense(5 layers,128 channels each, 3filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 75.27**\n",
    "\n",
    "    **3 and 4 have same parameter config**\n",
    "\n",
    "5. C(32,2);D(0.01);Dense(5 layers,32 channels each, 2filter size);C(32,2);P(2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(32,2);P(2);D(0.3);Dense(5 layers,32 channels each, 2filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 71.72**\n",
    "\n",
    "6. C(32,2);D(0.01);Dense(5 layers,32 channels each, 2filter size);C(64,2);P(2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2);P(2);D(0.3);Dense(5 layers,32 channels each, 2filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 74.79**\n",
    "\n",
    "7. C(32,2);D(0.01);Dense(5 layers,32 channels each, 2filter size);C(64,2,stride=2);;D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,stride=2);D(0.3);Dense(5 layers,32 channels each, 2filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 73.56**\n",
    "\n",
    "8. C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,stride=2);;D(0.3);Dense(5 layers,32 channels each, 2filter size);C(128,2, stride=2);D(0.4);Dense(5 layers,32 channels each, 2filter size);P(2);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 71.64**\n",
    "\n",
    "9. C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,stride=2);;D(0.3);Dense(5 layers,32 channels each, 2filter size);C(128,3, stride=2);D(0.4);Dense(5 layers,32 channels each, 3filter size);F \n",
    "\n",
    "      **epochs - 10**\n",
    "      **Test Accuracy -- 73.62**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyunbNPM-ArA"
   },
   "source": [
    "### Using Model.Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cg1sUAcfjqhc"
   },
   "outputs": [],
   "source": [
    "## Dense network\n",
    "\n",
    "img = tf.keras.Input(shape = (32,32,3))\n",
    "\n",
    "## Conv and dropout\n",
    "layerConv_1 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        input_shape=(32,32,3),\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(img)\n",
    "\n",
    "dropout_1 = tf.keras.layers.Dropout(0.2)(layerConv_1)\n",
    "\n",
    "\n",
    "## Dense layer 1\n",
    "layerDense_1_1 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_1)\n",
    "layerDense_1_2 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1), axis = 3))\n",
    "layerDense_1_3 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2), axis = 3))\n",
    "layerDense_1_4 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2, layerDense_1_3), axis = 3))\n",
    "layerDense_1_5 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2, layerDense_1_3, layerDense_1_4), axis = 3))\n",
    "\n",
    "\n",
    "## Conv pool and dropout layer 2\n",
    "layerConv_2 = tf.keras.layers.Conv2D(64,2,strides = 2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(layerDense_1_5)\n",
    "#maxpool_2 = tf.keras.layers.MaxPool2D((2,2))(layerConv_2)\n",
    "dropout_2 = tf.keras.layers.Dropout(0.3)(layerConv_2)\n",
    "\n",
    "\n",
    "\n",
    "## Dense layer 2\n",
    "layerDense_2_1 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_2)\n",
    "layerDense_2_2 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1), axis = 3))\n",
    "layerDense_2_3 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2), axis = 3))\n",
    "layerDense_2_4 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2, layerDense_2_3), axis = 3))\n",
    "layerDense_2_5 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2, layerDense_2_3, layerDense_2_4), axis = 3))\n",
    "\n",
    "\n",
    "## Conv pool and dropout layer 3\n",
    "layerConv_3 = tf.keras.layers.Conv2D(128,3,strides = 2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(layerDense_2_5)\n",
    "#maxpool_3 = tf.keras.layers.MaxPool2D((2,2))(layerConv_3)\n",
    "dropout_3 = tf.keras.layers.Dropout(0.4)(layerConv_3)\n",
    "\n",
    "## Dense layer 3\n",
    "layerDense_3_1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_3)\n",
    "layerDense_3_2 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1), axis = 3))\n",
    "layerDense_3_3 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2), axis = 3))\n",
    "layerDense_3_4 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2, layerDense_3_3), axis = 3))\n",
    "layerDense_3_5 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2, layerDense_3_3, layerDense_3_4), axis = 3))\n",
    "\n",
    "\n",
    "## Pooling and flattening\n",
    "#maxpool_4 = tf.keras.layers.MaxPool2D((2,2))(layerDense_3_5)\n",
    "layerFlatten = tf.keras.layers.Flatten()(layerDense_3_5)\n",
    "\n",
    "layerOutput = tf.keras.layers.Dense(10,kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                                    use_bias= True,bias_initializer='zeros' )(layerFlatten)\n",
    "\n",
    "\n",
    "opt = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "## Train accuracy metric\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDPaF7LCi9sM"
   },
   "outputs": [],
   "source": [
    "## Define the model\n",
    "model_cifar10 = tf.keras.Model(img, layerOutput, name = 'Cifar10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrwjDyq2s91_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Cifar10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4128        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 64)   0           dropout[0][0]                    \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 96)   0           dropout[0][0]                    \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 32)   12320       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           dropout[0][0]                    \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   16416       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 160)  0           dropout[0][0]                    \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 32)   20512       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   8256        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   8224        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 96)   0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   12320       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 128)  0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   16416       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 160)  0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   20512       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 192)  0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   24608       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 128)    36992       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 128)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 32)     36896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 160)    0           dropout_2[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 32)     46112       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 8, 8, 192)    0           dropout_2[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 32)     55328       concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 224)    0           dropout_2[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 32)     64544       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8, 8, 256)    0           dropout_2[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 32)     73760       concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           20490       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 486,474\n",
      "Trainable params: 486,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Get the summary of the model\n",
    "model_cifar10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jO_paHOG3sTO"
   },
   "outputs": [],
   "source": [
    "model_cifar10.compile(optimizer= opt,\n",
    "              loss = loss_fn,\n",
    "              metrics = [train_acc_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nwDwFjmD5Q_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.7440 - sparse_categorical_accuracy: 0.3646\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 39s 101ms/step - loss: 1.3830 - sparse_categorical_accuracy: 0.5003\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 40s 102ms/step - loss: 1.1675 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 1.0199 - sparse_categorical_accuracy: 0.63700s - loss: 1.0199 - sparse_categorical_accuracy: 0\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 0.9212 - sparse_categorical_accuracy: 0.6741\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 41s 104ms/step - loss: 0.8396 - sparse_categorical_accuracy: 0.7037\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.7807 - sparse_categorical_accuracy: 0.7234\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 39s 98ms/step - loss: 0.7226 - sparse_categorical_accuracy: 0.7438\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.6853 - sparse_categorical_accuracy: 0.7560\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.6349 - sparse_categorical_accuracy: 0.7761\n"
     ]
    }
   ],
   "source": [
    "history = model_cifar10.fit(train_data,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-20-2b56edfc58af>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-2b56edfc58af>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print('Default GPU Device:\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:\n",
    "\n",
    "    {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0dRmCdaAwQ6"
   },
   "outputs": [],
   "source": [
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model_cifar10(img_batch))\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgSbHExrBjz9"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_cifar10.evaluate(test_data)\n",
    "print(\"Loss: {} Accuracy: {}\".format(test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtFuyhRvG1UY"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaMXvAgx4tuj"
   },
   "source": [
    "### Tensorboard computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVccYaur4x83"
   },
   "source": [
    "![alt text](https://drive.google.com/uc?id=1-5GbqETI9ZQ-K1lSURmpU1NELhPTaP8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Uma4k2pFsgX"
   },
   "outputs": [],
   "source": [
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPvjsNWg5nJK"
   },
   "outputs": [],
   "source": [
    "model_cifar10.fit(train_data,epochs=10,callbacks =[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjgHP5QY5nRz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbJzaGGX5gWX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OXQBhT5m-LLl",
    "outputId": "773e87b1-8b87-4796-d388-81f34b57823a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.767300009727478\n"
     ]
    }
   ],
   "source": [
    "test_acc_metric = tf.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model_cifar10_fn(img_batch))\n",
    "\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xzaXkbGI-S_9"
   },
   "source": [
    "### Using tf.Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lotKA9VBJoPL"
   },
   "source": [
    "**Observations**\n",
    "\n",
    "C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,Stride-2);D(0.3);Dense(5 layers,32 channels each, 2filter size);C(128,3,stride-2);D(0.4);Dense(5 layers,32 channels each, 3filter size);F \n",
    "1. Epoch 10 = 73.3%\n",
    "2. Epoch 20 = 74.83%\n",
    "3. Epoch 50 = 75.45%\n",
    "\n",
    "C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,Stride-2);D(0.3);Dense(5 layers,32 channels each, 2filter size);C(64,2,stride-2);D(0.4);Dense(5 layers,32 channels each, 2filter size);F \n",
    "\n",
    "1. Epoch 10 = 70.60%\n",
    "2. Epoch 20 = 76.64%\n",
    "3. Epoch 50 = 77.67%\n",
    "\n",
    "C(32,2);D(0.2);Dense(5 layers,32 channels each, 2filter size);C(64,2,Stride-2);D(0.3);Dense(5 layers,64 channels each, 2filter size);C(64,2,stride-2);D(0.4);Dense(5 layers,64 channels each, 2filter size);F\n",
    "\n",
    "1. Epoch 10 = 73.75%\n",
    "2. Epoch 20 = 75.77%\n",
    "3. Epoch 30 = 76.73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01eszjRU-Re6"
   },
   "outputs": [],
   "source": [
    "## Dense network\n",
    "\n",
    "img = tf.keras.Input(shape = (32,32,3))\n",
    "\n",
    "\n",
    "\n",
    "## Conv and dropout\n",
    "layerConv_1 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        input_shape=(32,32,3),\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(img)\n",
    "\n",
    "dropout_1 = tf.keras.layers.Dropout(0.2)(layerConv_1)\n",
    "\n",
    "\n",
    "## Dense layer 1\n",
    "layerDense_1_1 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_1)\n",
    "layerDense_1_2 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1), axis = 3))\n",
    "layerDense_1_3 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2), axis = 3))\n",
    "layerDense_1_4 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2, layerDense_1_3), axis = 3))\n",
    "layerDense_1_5 = tf.keras.layers.Conv2D(32,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_1, layerDense_1_1, layerDense_1_2, layerDense_1_3, layerDense_1_4), axis = 3))\n",
    "\n",
    "\n",
    "## Conv pool and dropout layer 2\n",
    "layerConv_2 = tf.keras.layers.Conv2D(64,2,strides = 2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(layerDense_1_5)\n",
    "#maxpool_2 = tf.keras.layers.MaxPool2D((2,2))(layerConv_2)\n",
    "dropout_2 = tf.keras.layers.Dropout(0.3)(layerConv_2)\n",
    "\n",
    "\n",
    "\n",
    "## Dense layer 2\n",
    "layerDense_2_1 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_2)\n",
    "layerDense_2_2 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1), axis = 3))\n",
    "layerDense_2_3 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2), axis = 3))\n",
    "layerDense_2_4 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2, layerDense_2_3), axis = 3))\n",
    "layerDense_2_5 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_2, layerDense_2_1, layerDense_2_2, layerDense_2_3, layerDense_2_4), axis = 3))\n",
    "\n",
    "\n",
    "## Conv pool and dropout layer 3\n",
    "layerConv_3 = tf.keras.layers.Conv2D(64,2,strides = 2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(layerDense_2_5)\n",
    "#maxpool_3 = tf.keras.layers.MaxPool2D((2,2))(layerConv_3)\n",
    "dropout_3 = tf.keras.layers.Dropout(0.4)(layerConv_3)\n",
    "\n",
    "## Dense layer 3\n",
    "layerDense_3_1 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(dropout_3)\n",
    "layerDense_3_2 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1), axis = 3))\n",
    "layerDense_3_3 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2), axis = 3))\n",
    "layerDense_3_4 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2, layerDense_3_3), axis = 3))\n",
    "layerDense_3_5 = tf.keras.layers.Conv2D(64,2,padding='same',activation='relu',\n",
    "                        kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                        use_bias = True,bias_initializer='zeros')(tf.keras.layers.concatenate((dropout_3, layerDense_3_1, layerDense_3_2, layerDense_3_3, layerDense_3_4), axis = 3))\n",
    "\n",
    "\n",
    "## Pooling and flattening\n",
    "#maxpool_4 = tf.keras.layers.MaxPool2D((2,2))(layerDense_3_5)\n",
    "layerFlatten = tf.keras.layers.Flatten()(layerDense_3_5)\n",
    "\n",
    "layerOutput = tf.keras.layers.Dense(10,kernel_initializer = tf.keras.initializers.RandomUniform(minval=-0.1, maxval=0.1, seed=None),\n",
    "                                    use_bias= True,bias_initializer='zeros' )(layerFlatten)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKPHoO5S-RfG"
   },
   "outputs": [],
   "source": [
    "## Define the model\n",
    "model_cifar10_fn = tf.keras.Model(img, layerOutput, name = 'Cifar10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8O54rtEEAUL"
   },
   "outputs": [],
   "source": [
    "model_cifar10_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7f8FV6oH-LbW"
   },
   "outputs": [],
   "source": [
    "\n",
    "opt = tf.optimizers.Adam()\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "## Train accuracy metric\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9fMq02W-_7V"
   },
   "outputs": [],
   "source": [
    "# stereotypical train-step-with-function-annotation\n",
    "\n",
    "@tf.function\n",
    "def train_step(imgs, lbls):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model_cifar10_fn(imgs,training=True)\n",
    "        loss = loss_fn(lbls, logits)\n",
    "\n",
    "    varis = model_cifar10_fn.trainable_variables\n",
    "    grads = tape.gradient(loss, varis)\n",
    "    opt.apply_gradients(zip(grads, varis))\n",
    "\n",
    "    return loss, logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eq-HQwtI-LCI",
    "outputId": "99e1a2c1-4323-43fb-a3db-7143ad31955b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Start of epoch 0\n",
      "Loss: 0.3725576400756836 Accuracy: 0.875\n",
      "Loss: 0.4120078384876251 Accuracy: 0.8671875\n",
      "Loss: 0.34093543887138367 Accuracy: 0.8828125\n",
      "==========================================================================================\n",
      "Start of epoch 1\n",
      "Loss: 0.2901102304458618 Accuracy: 0.8984375\n",
      "Loss: 0.32507985830307007 Accuracy: 0.875\n",
      "Loss: 0.5197538137435913 Accuracy: 0.796875\n",
      "Loss: 0.36152327060699463 Accuracy: 0.8515625\n",
      "==========================================================================================\n",
      "Start of epoch 2\n",
      "Loss: 0.20199868083000183 Accuracy: 0.9296875\n",
      "Loss: 0.3061571717262268 Accuracy: 0.8984375\n",
      "Loss: 0.342501699924469 Accuracy: 0.8828125\n",
      "Loss: 0.44678550958633423 Accuracy: 0.859375\n",
      "==========================================================================================\n",
      "Start of epoch 3\n",
      "Loss: 0.26982182264328003 Accuracy: 0.90625\n",
      "Loss: 0.38213470578193665 Accuracy: 0.84375\n",
      "Loss: 0.22671423852443695 Accuracy: 0.9453125\n",
      "Loss: 0.37183207273483276 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 4\n",
      "Loss: 0.36144572496414185 Accuracy: 0.8671875\n",
      "Loss: 0.2409334033727646 Accuracy: 0.9140625\n",
      "Loss: 0.2540138363838196 Accuracy: 0.890625\n",
      "Loss: 0.2537589967250824 Accuracy: 0.9140625\n",
      "==========================================================================================\n",
      "Start of epoch 5\n",
      "Loss: 0.32251089811325073 Accuracy: 0.8984375\n",
      "Loss: 0.283016562461853 Accuracy: 0.9140625\n",
      "Loss: 0.35460540652275085 Accuracy: 0.8828125\n",
      "Loss: 0.2224941998720169 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 6\n",
      "Loss: 0.27199602127075195 Accuracy: 0.875\n",
      "Loss: 0.33383673429489136 Accuracy: 0.890625\n",
      "Loss: 0.24003612995147705 Accuracy: 0.8671875\n",
      "Loss: 0.4087291955947876 Accuracy: 0.8671875\n",
      "==========================================================================================\n",
      "Start of epoch 7\n",
      "Loss: 0.3558974266052246 Accuracy: 0.890625\n",
      "Loss: 0.2702298164367676 Accuracy: 0.8984375\n",
      "Loss: 0.301924467086792 Accuracy: 0.8984375\n",
      "Loss: 0.24195124208927155 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 8\n",
      "Loss: 0.312717080116272 Accuracy: 0.8828125\n",
      "Loss: 0.21953707933425903 Accuracy: 0.921875\n",
      "Loss: 0.268060564994812 Accuracy: 0.9296875\n",
      "Loss: 0.30098623037338257 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 9\n",
      "Loss: 0.2902592122554779 Accuracy: 0.890625\n",
      "Loss: 0.39383047819137573 Accuracy: 0.8671875\n",
      "Loss: 0.3062114715576172 Accuracy: 0.890625\n",
      "Loss: 0.20030063390731812 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 10\n",
      "Loss: 0.19837850332260132 Accuracy: 0.9375\n",
      "Loss: 0.32256996631622314 Accuracy: 0.8828125\n",
      "Loss: 0.2770920395851135 Accuracy: 0.9140625\n",
      "Loss: 0.18725448846817017 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 11\n",
      "Loss: 0.40679529309272766 Accuracy: 0.828125\n",
      "Loss: 0.25564873218536377 Accuracy: 0.8984375\n",
      "Loss: 0.32615476846694946 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 12\n",
      "Loss: 0.24748440086841583 Accuracy: 0.9140625\n",
      "Loss: 0.291435182094574 Accuracy: 0.890625\n",
      "Loss: 0.19521041214466095 Accuracy: 0.9296875\n",
      "Loss: 0.20632398128509521 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 13\n",
      "Loss: 0.3056306838989258 Accuracy: 0.90625\n",
      "Loss: 0.19510850310325623 Accuracy: 0.921875\n",
      "Loss: 0.3092549443244934 Accuracy: 0.8828125\n",
      "Loss: 0.45415157079696655 Accuracy: 0.8515625\n",
      "==========================================================================================\n",
      "Start of epoch 14\n",
      "Loss: 0.22154119610786438 Accuracy: 0.8671875\n",
      "Loss: 0.19088466465473175 Accuracy: 0.9453125\n",
      "Loss: 0.3291719853878021 Accuracy: 0.8828125\n",
      "Loss: 0.39468371868133545 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 15\n",
      "Loss: 0.17196808755397797 Accuracy: 0.953125\n",
      "Loss: 0.250686913728714 Accuracy: 0.9140625\n",
      "Loss: 0.2388286143541336 Accuracy: 0.890625\n",
      "Loss: 0.26162466406822205 Accuracy: 0.9140625\n",
      "==========================================================================================\n",
      "Start of epoch 16\n",
      "Loss: 0.18519678711891174 Accuracy: 0.90625\n",
      "Loss: 0.2828613221645355 Accuracy: 0.90625\n",
      "Loss: 0.2689407467842102 Accuracy: 0.90625\n",
      "Loss: 0.19651876389980316 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 17\n",
      "Loss: 0.2193596065044403 Accuracy: 0.9140625\n",
      "Loss: 0.374409019947052 Accuracy: 0.8984375\n",
      "Loss: 0.22805190086364746 Accuracy: 0.9140625\n",
      "Loss: 0.36063677072525024 Accuracy: 0.8515625\n",
      "==========================================================================================\n",
      "Start of epoch 18\n",
      "Loss: 0.35715141892433167 Accuracy: 0.8515625\n",
      "Loss: 0.20015713572502136 Accuracy: 0.9296875\n",
      "Loss: 0.23942580819129944 Accuracy: 0.90625\n",
      "Loss: 0.3431190550327301 Accuracy: 0.8828125\n",
      "==========================================================================================\n",
      "Start of epoch 19\n",
      "Loss: 0.28443750739097595 Accuracy: 0.90625\n",
      "Loss: 0.24128541350364685 Accuracy: 0.9296875\n",
      "Loss: 0.31567561626434326 Accuracy: 0.9140625\n",
      "Loss: 0.20796799659729004 Accuracy: 0.9296875\n",
      "==========================================================================================\n",
      "Start of epoch 20\n",
      "Loss: 0.19916585087776184 Accuracy: 0.921875\n",
      "Loss: 0.2439562976360321 Accuracy: 0.9140625\n",
      "Loss: 0.29682475328445435 Accuracy: 0.890625\n",
      "Loss: 0.2944621741771698 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 21\n",
      "Loss: 0.29011785984039307 Accuracy: 0.875\n",
      "Loss: 0.28910064697265625 Accuracy: 0.9140625\n",
      "Loss: 0.25999438762664795 Accuracy: 0.8828125\n",
      "Loss: 0.1765395551919937 Accuracy: 0.921875\n",
      "==========================================================================================\n",
      "Start of epoch 22\n",
      "Loss: 0.28033268451690674 Accuracy: 0.90625\n",
      "Loss: 0.2070925384759903 Accuracy: 0.9375\n",
      "Loss: 0.2618606984615326 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 23\n",
      "Loss: 0.1667759120464325 Accuracy: 0.9375\n",
      "Loss: 0.17971403896808624 Accuracy: 0.9453125\n",
      "Loss: 0.2218441367149353 Accuracy: 0.9140625\n",
      "Loss: 0.2737160623073578 Accuracy: 0.8828125\n",
      "==========================================================================================\n",
      "Start of epoch 24\n",
      "Loss: 0.2578432857990265 Accuracy: 0.90625\n",
      "Loss: 0.1692626178264618 Accuracy: 0.9375\n",
      "Loss: 0.1591998189687729 Accuracy: 0.9375\n",
      "Loss: 0.22658029198646545 Accuracy: 0.8984375\n",
      "==========================================================================================\n",
      "Start of epoch 25\n",
      "Loss: 0.1757681965827942 Accuracy: 0.9375\n",
      "Loss: 0.2837972044944763 Accuracy: 0.90625\n",
      "Loss: 0.189570352435112 Accuracy: 0.9296875\n",
      "Loss: 0.2334575355052948 Accuracy: 0.8984375\n",
      "==========================================================================================\n",
      "Start of epoch 26\n",
      "Loss: 0.2544693052768707 Accuracy: 0.9140625\n",
      "Loss: 0.231563001871109 Accuracy: 0.921875\n",
      "Loss: 0.33857637643814087 Accuracy: 0.9140625\n",
      "Loss: 0.24284720420837402 Accuracy: 0.890625\n",
      "==========================================================================================\n",
      "Start of epoch 27\n",
      "Loss: 0.30024388432502747 Accuracy: 0.8984375\n",
      "Loss: 0.13367336988449097 Accuracy: 0.9453125\n",
      "Loss: 0.2013985514640808 Accuracy: 0.9296875\n",
      "Loss: 0.30671000480651855 Accuracy: 0.921875\n",
      "==========================================================================================\n",
      "Start of epoch 28\n",
      "Loss: 0.23250985145568848 Accuracy: 0.90625\n",
      "Loss: 0.12797844409942627 Accuracy: 0.9453125\n",
      "Loss: 0.1835188865661621 Accuracy: 0.9375\n",
      "Loss: 0.19173657894134521 Accuracy: 0.9296875\n",
      "==========================================================================================\n",
      "Start of epoch 29\n",
      "Loss: 0.3535119891166687 Accuracy: 0.90625\n",
      "Loss: 0.1817818135023117 Accuracy: 0.921875\n",
      "Loss: 0.2616441249847412 Accuracy: 0.90625\n",
      "Loss: 0.3060342073440552 Accuracy: 0.875\n",
      "==========================================================================================\n",
      "Start of epoch 30\n",
      "Loss: 0.18294580280780792 Accuracy: 0.9296875\n",
      "Loss: 0.3462558090686798 Accuracy: 0.875\n",
      "Loss: 0.24176384508609772 Accuracy: 0.8984375\n",
      "Loss: 0.30850204825401306 Accuracy: 0.8515625\n",
      "==========================================================================================\n",
      "Start of epoch 31\n",
      "Loss: 0.2075246274471283 Accuracy: 0.921875\n",
      "Loss: 0.29720669984817505 Accuracy: 0.8984375\n",
      "Loss: 0.20829817652702332 Accuracy: 0.953125\n",
      "Loss: 0.16641584038734436 Accuracy: 0.953125\n",
      "==========================================================================================\n",
      "Start of epoch 32\n",
      "Loss: 0.3007870316505432 Accuracy: 0.859375\n",
      "Loss: 0.25731533765792847 Accuracy: 0.9140625\n",
      "Loss: 0.20780517160892487 Accuracy: 0.9296875\n",
      "Loss: 0.12595507502555847 Accuracy: 0.9609375\n",
      "==========================================================================================\n",
      "Start of epoch 33\n",
      "Loss: 0.2860555350780487 Accuracy: 0.890625\n",
      "Loss: 0.22735348343849182 Accuracy: 0.9140625\n",
      "Loss: 0.21150383353233337 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 34\n",
      "Loss: 0.34344062209129333 Accuracy: 0.875\n",
      "Loss: 0.15140444040298462 Accuracy: 0.953125\n",
      "Loss: 0.24829435348510742 Accuracy: 0.921875\n",
      "Loss: 0.14268863201141357 Accuracy: 0.9453125\n",
      "==========================================================================================\n",
      "Start of epoch 35\n",
      "Loss: 0.3988415002822876 Accuracy: 0.8671875\n",
      "Loss: 0.1471647024154663 Accuracy: 0.9609375\n",
      "Loss: 0.19298997521400452 Accuracy: 0.9453125\n",
      "Loss: 0.21233625710010529 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 36\n",
      "Loss: 0.10543784499168396 Accuracy: 0.9453125\n",
      "Loss: 0.18847109377384186 Accuracy: 0.921875\n",
      "Loss: 0.204872265458107 Accuracy: 0.921875\n",
      "Loss: 0.2981492280960083 Accuracy: 0.8828125\n",
      "==========================================================================================\n",
      "Start of epoch 37\n",
      "Loss: 0.1339361071586609 Accuracy: 0.9375\n",
      "Loss: 0.11904006451368332 Accuracy: 0.9296875\n",
      "Loss: 0.1371522843837738 Accuracy: 0.9453125\n",
      "Loss: 0.29167354106903076 Accuracy: 0.921875\n",
      "==========================================================================================\n",
      "Start of epoch 38\n",
      "Loss: 0.1555662304162979 Accuracy: 0.9609375\n",
      "Loss: 0.1646716594696045 Accuracy: 0.953125\n",
      "Loss: 0.3198625147342682 Accuracy: 0.90625\n",
      "Loss: 0.2620624601840973 Accuracy: 0.9140625\n",
      "==========================================================================================\n",
      "Start of epoch 39\n",
      "Loss: 0.14891524612903595 Accuracy: 0.9375\n",
      "Loss: 0.2510087192058563 Accuracy: 0.9140625\n",
      "Loss: 0.12972746789455414 Accuracy: 0.96875\n",
      "Loss: 0.159896582365036 Accuracy: 0.9609375\n",
      "==========================================================================================\n",
      "Start of epoch 40\n",
      "Loss: 0.17657770216464996 Accuracy: 0.9453125\n",
      "Loss: 0.13437238335609436 Accuracy: 0.9375\n",
      "Loss: 0.2358511984348297 Accuracy: 0.90625\n",
      "Loss: 0.2947082817554474 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 41\n",
      "Loss: 0.2545939087867737 Accuracy: 0.9140625\n",
      "Loss: 0.15131831169128418 Accuracy: 0.9609375\n",
      "Loss: 0.20975881814956665 Accuracy: 0.921875\n",
      "Loss: 0.07992670685052872 Accuracy: 0.96875\n",
      "==========================================================================================\n",
      "Start of epoch 42\n",
      "Loss: 0.29741084575653076 Accuracy: 0.8984375\n",
      "Loss: 0.1349019706249237 Accuracy: 0.9453125\n",
      "Loss: 0.11442151665687561 Accuracy: 0.96875\n",
      "Loss: 0.282551646232605 Accuracy: 0.8984375\n",
      "==========================================================================================\n",
      "Start of epoch 43\n",
      "Loss: 0.16740331053733826 Accuracy: 0.90625\n",
      "Loss: 0.2027186155319214 Accuracy: 0.921875\n",
      "Loss: 0.21158988773822784 Accuracy: 0.8984375\n",
      "Loss: 0.2031555473804474 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 44\n",
      "Loss: 0.16203658282756805 Accuracy: 0.953125\n",
      "Loss: 0.34905219078063965 Accuracy: 0.8984375\n",
      "Loss: 0.13020746409893036 Accuracy: 0.9375\n",
      "==========================================================================================\n",
      "Start of epoch 45\n",
      "Loss: 0.18313880264759064 Accuracy: 0.9453125\n",
      "Loss: 0.31784194707870483 Accuracy: 0.9140625\n",
      "Loss: 0.299650102853775 Accuracy: 0.9296875\n",
      "Loss: 0.1159476637840271 Accuracy: 0.96875\n",
      "==========================================================================================\n",
      "Start of epoch 46\n",
      "Loss: 0.15517699718475342 Accuracy: 0.9375\n",
      "Loss: 0.2405891865491867 Accuracy: 0.921875\n",
      "Loss: 0.16586078703403473 Accuracy: 0.9453125\n",
      "Loss: 0.22483377158641815 Accuracy: 0.921875\n",
      "==========================================================================================\n",
      "Start of epoch 47\n",
      "Loss: 0.1215028315782547 Accuracy: 0.9453125\n",
      "Loss: 0.16039231419563293 Accuracy: 0.9296875\n",
      "Loss: 0.24733881652355194 Accuracy: 0.921875\n",
      "Loss: 0.19844713807106018 Accuracy: 0.90625\n",
      "==========================================================================================\n",
      "Start of epoch 48\n",
      "Loss: 0.3118494153022766 Accuracy: 0.890625\n",
      "Loss: 0.15070247650146484 Accuracy: 0.953125\n",
      "Loss: 0.26869070529937744 Accuracy: 0.9453125\n",
      "Loss: 0.10868632793426514 Accuracy: 0.9609375\n",
      "==========================================================================================\n",
      "Start of epoch 49\n",
      "Loss: 0.2711407542228699 Accuracy: 0.90625\n",
      "Loss: 0.12913179397583008 Accuracy: 0.9453125\n",
      "Loss: 0.15926361083984375 Accuracy: 0.9609375\n",
      "Loss: 0.2220306545495987 Accuracy: 0.921875\n",
      "took 1425.2716643810272 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "steps = 0\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "  print(\"=\"*90)\n",
    "  print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "  for img_batch,lbl_batch in train_data:\n",
    "      steps = steps+1\n",
    "      loss, logits = train_step(img_batch, lbl_batch)\n",
    "\n",
    "      if not steps % 100:\n",
    "          train_acc_metric(lbl_batch, logits)\n",
    "          acc = train_acc_metric.result()\n",
    "          print(\"Loss: {} Accuracy: {}\".format(loss, acc))\n",
    "          train_acc_metric.reset_states()\n",
    "\n",
    "\n",
    "stop = time.time()\n",
    "print(\"took {} seconds\\n\".format(stop-start))\n",
    "#start = time.time()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "IDL_Assignment4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
